{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'resized_train/'\n",
    "names = os.listdir(train_folder)\n",
    "if '.DS_Store' in names:\n",
    "    names.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs = []\n",
    "negative_pairs = []\n",
    "for index, name in enumerate(names):\n",
    "    copy_names = names.copy()\n",
    "    copy_names.remove(name)\n",
    "    print(index)\n",
    "    new_path = train_folder + name + '/'\n",
    "    images = os.listdir(new_path)\n",
    "    \n",
    "    images = [new_path + s for s in images]\n",
    "    combinations = itertools.combinations(images, 2)\n",
    "    \n",
    "    temp = []\n",
    "    for comb in combinations:\n",
    "        temp.append(list(comb))\n",
    "    \n",
    "    positive_pairs.extend(random.choices(temp, k = 80))   \n",
    "    after = len(positive_pairs)\n",
    "    \n",
    "    negative_folders = random.sample(copy_names, 80)\n",
    "    \n",
    "    neg_imgs = []\n",
    "    for negative in negative_folders:\n",
    "        negative_path = train_folder + negative + '/'\n",
    "        neg_imgs.append(negative_path + random.sample(os.listdir(negative_path), 1)[0])\n",
    "    \n",
    "    positions = [0,1]\n",
    "    \n",
    "    for each in neg_imgs:\n",
    "        true = random.sample(images, 1)[0]\n",
    "        a = [0,0]\n",
    "        pos = random.sample(positions, 1)\n",
    "        a[pos[0]] = true\n",
    "        if pos[0] == 1:\n",
    "            a[0] = each\n",
    "        else:\n",
    "            a[1] = each\n",
    "        negative_pairs.append(a)\n",
    "    \n",
    "print(len(positive_pairs), len(negative_pairs))\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d268fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positive_pairs), len(negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9857ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "labels.extend([1] * len(positive_pairs))\n",
    "labels.extend([0] * len(negative_pairs))\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "pairs.extend(positive_pairs)\n",
    "pairs.extend(negative_pairs)\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e13c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del positive_pairs\n",
    "del negative_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(pairs)\n",
    "df_train.columns = ['img1_name', 'img2_name']\n",
    "df_train['label'] = labels\n",
    "print(df_train.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ea7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ecc475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac = 1)\n",
    "df_train = df_train.reset_index(drop = True)\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098dc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_only = pd.read_csv('dataset/val.csv') \n",
    "print(df_val_only.head(4)), df_val_only.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab7178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(img1, img2, orb, bf):\n",
    "    kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "    try:\n",
    "        if des1.all()!=None and des2.all()!=None:\n",
    "            return des1, des2\n",
    "            \n",
    "    except AttributeError:\n",
    "        return [], []\n",
    "    except ValueError:\n",
    "        return [], []\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac12071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_df(df, condition):\n",
    "    empty_indices = []\n",
    "    empty_labels = []\n",
    "    orb = cv2.ORB_create(90)\n",
    "    bf = cv2.BFMatcher()\n",
    "    img1_features = []\n",
    "    img2_features = []\n",
    "    label = []\n",
    "    errors = []\n",
    "    if condition == 'train':\n",
    "        for index, row in df.iterrows():\n",
    "            print(index)\n",
    "            img1 = Image.open(row['img1_name'])\n",
    "            img2 = Image.open(row['img2_name'])\n",
    "\n",
    "            img1 = np.asarray(img1)\n",
    "            img2 = np.asarray(img2)\n",
    "\n",
    "            img1 = np.expand_dims(img1, axis = -1)\n",
    "            img2 = np.expand_dims(img2, axis = -1)\n",
    "\n",
    "            m_list, n_list = get_feature(img1, img2, orb, bf)\n",
    "            if len(m_list) == 0 or len(n_list) == 0:\n",
    "                continue\n",
    "            img1_features.append(m_list)\n",
    "            img2_features.append(n_list)\n",
    "            label.append(row['label'])\n",
    "            \n",
    "    else:\n",
    "        for index, row in df.iterrows():\n",
    "            print(index)\n",
    "            img1 = Image.open('val_resize/' + row['img1_name'])\n",
    "            img2 = Image.open('val_resize/' + row['img2_name'])\n",
    "\n",
    "            img1 = np.asarray(img1)\n",
    "            img2 = np.asarray(img2)\n",
    "\n",
    "            img1 = np.expand_dims(img1, axis = -1)\n",
    "            img2 = np.expand_dims(img2, axis = -1)\n",
    "\n",
    "            m_list, n_list = get_feature(img1, img2, orb, bf)\n",
    "            if len(m_list) == 0 or len(n_list) <= 1:\n",
    "                empty_indices.append(index)\n",
    "                empty_labels.append(row['label'])\n",
    "                continue\n",
    "            img1_features.append(m_list)\n",
    "            img2_features.append(n_list)\n",
    "            label.append(row['label'])\n",
    "        return img1_features, img2_features, label, empty_indices, empty_labels\n",
    "        \n",
    "    return img1_features, img2_features, label\n",
    "        \n",
    "img1_features_train, img2_features_train, label_train = over_df(df_train, 'train')\n",
    "img1_features_val, img2_features_val, label_val, empty_indices, empty_labels = over_df(df_val_only, 'val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd06fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label_val), len(empty_labels), set(empty_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for each in img1_features_train:\n",
    "    lengths.append(len(each))\n",
    "maxlen = max(lengths)\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_features_train = tf.keras.utils.pad_sequences(img1_features_train, maxlen = maxlen)\n",
    "img2_features_train = tf.keras.utils.pad_sequences(img2_features_train, maxlen = maxlen)\n",
    "\n",
    "img1_features_val = tf.keras.utils.pad_sequences(img1_features_val, maxlen = maxlen)\n",
    "img2_features_val = tf.keras.utils.pad_sequences(img2_features_val, maxlen = maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151494db",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_features_train = np.array(img1_features_train)\n",
    "img2_features_train = np.array(img2_features_train)\n",
    "label_train = np.array(label_train)\n",
    "\n",
    "img1_features_val = np.array(img1_features_val)\n",
    "img2_features_val = np.array(img2_features_val)\n",
    "label_val = np.array(label_val)\n",
    "\n",
    "img1_features_train.shape, img2_features_train.shape, label_train.shape, img1_features_val.shape, img2_features_val.shape, label_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_features_train_shape = img1_features_train.shape\n",
    "img2_features_train_shape = img2_features_train.shape\n",
    "img1_features_val_shape = img1_features_val.shape\n",
    "img2_features_val_shape = img2_features_val.shape\n",
    "\n",
    "img1_features_train = np.reshape(img1_features_train, (img1_features_train.shape[0], img1_features_train.shape[1] * img1_features_train.shape[2]))\n",
    "img2_features_train = np.reshape(img2_features_train, (img2_features_train.shape[0], img2_features_train.shape[1] * img2_features_train.shape[2]))\n",
    "img1_features_val = np.reshape(img1_features_val, (img1_features_val.shape[0], img1_features_val.shape[1] * img1_features_val.shape[2]))\n",
    "img2_features_val = np.reshape(img2_features_val, (img2_features_val.shape[0], img2_features_val.shape[1] * img2_features_val.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b811719",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler_m = preprocessing.StandardScaler()\n",
    "mm_scaler_m.fit(img1_features_train)\n",
    "m_train = mm_scaler_m.transform(img1_features_train)\n",
    "m_val = mm_scaler_m.transform(img1_features_val)\n",
    "\n",
    "mm_scaler_n = preprocessing.StandardScaler()\n",
    "mm_scaler_n.fit(img2_features_train)\n",
    "n_train = mm_scaler_n.transform(img2_features_train)\n",
    "n_val = mm_scaler_n.transform(img2_features_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = np.reshape(m_train, (img1_features_train_shape[0], img1_features_train_shape[1], img1_features_train_shape[2]))\n",
    "m_val = np.reshape(m_val, (img1_features_val_shape[0], img1_features_val_shape[1], img1_features_val_shape[2]))\n",
    "n_train = np.reshape(n_train, (img2_features_train_shape[0], img2_features_train_shape[1], img2_features_train_shape[2]))\n",
    "n_val = np.reshape(n_val, (img2_features_val_shape[0], img2_features_val_shape[1], img2_features_val_shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train.shape, n_train.shape, label_train.shape, m_val.shape, n_val.shape, label_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a41c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs_1 = tf.keras.Input(shape = (maxlen, 32))\n",
    "inputs_2 = tf.keras.Input(shape = (maxlen, 32))\n",
    "\n",
    "\n",
    "attention3 = tf.keras.layers.MultiHeadAttention(num_heads = 2, key_dim = 16)\n",
    "output_tensor = attention3(inputs_1, inputs_2)\n",
    "output_tensor = tf.keras.layers.Dropout(0.2)(output_tensor)\n",
    "merge = tf.keras.layers.Add()([inputs_1, output_tensor])\n",
    "merge = tf.keras.layers.LayerNormalization()(merge)\n",
    "out = tf.keras.layers.Dense(32, activation = 'relu')(merge)\n",
    "out = tf.keras.layers.Dense(32, activation = 'relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.2)(out)\n",
    "merge = tf.keras.layers.Add()([merge, out])\n",
    "merge = tf.keras.layers.LayerNormalization()(merge)\n",
    "\n",
    "merge = tf.keras.layers.GlobalAveragePooling1D()(merge)\n",
    "\n",
    "y = tf.keras.layers.Dense(64, activation = 'relu', kernel_regularizer = tf.keras.regularizers.L2(l2=0.01))(merge)\n",
    "y = tf.keras.layers.Dropout(0.3)(y)\n",
    "y = tf.keras.layers.Dense(1, activation = 'sigmoid')(y)\n",
    "\n",
    "\n",
    "model = tf.keras.Model([inputs_1, inputs_2], y)\n",
    "print(model.summary())\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0005\n",
    "    drop = 0.09\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]\n",
    "    \n",
    "adam = tf.keras.optimizers.legacy.Adam(learning_rate=0.0005, amsgrad=False)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = adam)\n",
    "model.fit([m_train, n_train], label_train, epochs = 100, batch_size = 256, \n",
    "          validation_data = ([m_val, n_val], label_val), callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7799125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(df):\n",
    "    orb = cv2.ORB_create(90)\n",
    "    bf = cv2.BFMatcher()\n",
    "    img1_features = []\n",
    "    img2_features = []\n",
    "    label = []\n",
    "    predictions = []\n",
    "    img1_name = []\n",
    "    img2_name = []\n",
    "    prediction_probs = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        print(index)\n",
    "        img1_name.append(row['img1_name'])\n",
    "        img2_name.append(row['img2_name'])\n",
    "        img1 = Image.open('val_resize/' + row['img1_name'])\n",
    "        img2 = Image.open('val_resize/' + row['img2_name'])\n",
    "\n",
    "        img1 = np.asarray(img1)\n",
    "        img2 = np.asarray(img2)\n",
    "\n",
    "        img1 = np.expand_dims(img1, axis = -1)\n",
    "        img2 = np.expand_dims(img2, axis = -1)\n",
    "\n",
    "        m_list, n_list = get_feature(img1, img2, orb, bf)\n",
    "        if len(m_list) == 0 or len(n_list) <= 1:\n",
    "            temp_prob = np.random.rand()\n",
    "            prediction_probs.append(temp_prob)\n",
    "            if temp_prob >= 0.5:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "            label.append(row['label'])\n",
    "            \n",
    "        else:\n",
    "            img1_features_val = []\n",
    "            img2_features_val = []\n",
    "            img1_features_val.append(m_list)\n",
    "            img2_features_val.append(n_list)\n",
    "            img1_features_val = tf.keras.utils.pad_sequences(img1_features_val, maxlen = maxlen)\n",
    "            img2_features_val = tf.keras.utils.pad_sequences(img2_features_val, maxlen = maxlen)\n",
    "\n",
    "            img1_features_val = np.array(img1_features_val)\n",
    "            img2_features_val = np.array(img2_features_val)\n",
    "\n",
    "            img1_features_val_shape = img1_features_val.shape\n",
    "            img2_features_val_shape = img2_features_val.shape\n",
    "\n",
    "            img1_features_val = np.reshape(img1_features_val, (img1_features_val.shape[0], img1_features_val.shape[1] * img1_features_val.shape[2]))\n",
    "            img2_features_val = np.reshape(img2_features_val, (img2_features_val.shape[0], img2_features_val.shape[1] * img2_features_val.shape[2]))\n",
    "\n",
    "            m_val = mm_scaler_m.transform(img1_features_val)\n",
    "            n_val = mm_scaler_n.transform(img2_features_val)\n",
    "\n",
    "            m_val = np.reshape(m_val, (img1_features_val_shape[0], img1_features_val_shape[1], img1_features_val_shape[2]))\n",
    "            n_val = np.reshape(n_val, (img2_features_val_shape[0], img2_features_val_shape[1], img2_features_val_shape[2]))\n",
    "\n",
    "            model_pred = model.predict([m_val, n_val])\n",
    "            prediction_probs.append(model_pred[0][0])\n",
    "            if model_pred >= 0.5:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "            label.append(row['label'])\n",
    "          \n",
    "    return prediction_probs, predictions, label, img1_name, img2_name\n",
    "        \n",
    "prediction_probs, predictions, label, img1_name, img2_name = make_predictions(df_val_only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(label, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(label, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd14375",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(label, prediction_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f55b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"writer_model.h5\")\n",
    "model.save_weights('writer_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eeda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mm_scaler_m.pkl','wb') as f:\n",
    "    pickle.dump(mm_scaler_m, f)\n",
    "with open('mm_scaler_n.pkl','wb') as f:\n",
    "    pickle.dump(mm_scaler_n, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2636d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
